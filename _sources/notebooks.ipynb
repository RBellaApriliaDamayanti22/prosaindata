{"cells":[{"cell_type":"markdown","source":["# PSD"],"metadata":{"id":"yTXkMLGWu06l"}},{"cell_type":"markdown","metadata":{"id":"mESvRT8tUjcR"},"source":["## TUGAS 1 (CRAWLING TWITTER) "]},{"cell_type":"markdown","metadata":{"id":"-7XBj_vOSS5U"},"source":["### 1. Install snscrape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LPu4eLSOUxhI"},"outputs":[],"source":["!pip install snscrape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RbPt2BW0hBwy"},"outputs":[],"source":["from tqdm.notebook import tqdm\n","from ipywidgets import FloatProgress\n","import csv\n","import pandas as pd\n","import snscrape.modules.twitter as sntwitter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvr3GuehU2D3"},"outputs":[],"source":["scraper=sntwitter.TwitterSearchScraper(\"sandiuno\")\n","tweets=[]\n","n_tweets=500\n","for i, tweet in tqdm(enumerate(scraper.get_items()), total=n_tweets):\n","    data=[\n","        tweet.user.username, \n","        tweet.rawContent, \n","        tweet.user.location,\n","    ]\n","    tweets.append(data)\n","    if i > n_tweets:\n","        break\n","tweet_df=pd.DataFrame(tweets, columns=['@Username','Tweet', 'Lokasi'])\n","tweet_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lc8korPLiQMY"},"outputs":[],"source":["tweet_df.to_csv('Twitter-.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"0wNMcBkEVN7u"},"source":["## TUGAS 2 (Crawling data Website https://pta.trunojoyo.ac.id/ )"]},{"cell_type":"markdown","metadata":{"id":"aDx24WXHVV47"},"source":["### 1. Install modul Beautifulsoup dan request and Import library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_AwIrfUbVdQN"},"outputs":[],"source":["import requests \n","from bs4 import BeautifulSoup \n","import csv\n","import pandas as pd\n","#agent user : supaya web server menampilkan konten yang dimiliki sesuai dengan OS yang kita gunakan, jadi web server tau browser dan OS yang kita gunakan\n","hades = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}"]},{"cell_type":"markdown","metadata":{"id":"OT70O_3TVmGp"},"source":["### Peroses crawling menggunakan bs4 dan request\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ptB2gW0BVnMw"},"outputs":[],"source":["#Inisialisasi Link URL\n","url = 'https://pta.trunojoyo.ac.id/c_search/byprod/10/'\n","\n","headers={\n","    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'\n","    }\n","\n","#Inisialisai list untuk menginputkan hasil crawling kedalam sebuah list\n","listJudul = []\n","listPenulis = []\n","listAbstrak = []\n","\n","#proses perulangan untuk crawling data\n","for page in range(1,172):\n","  req = requests.get(url+str(page), headers=headers)\n","  soup = BeautifulSoup(req.text, 'html.parser')\n","  items = soup.findAll('li',{'data-id':'id-1'})\n","  for it in items:\n","    try: link = it.find('a', 'gray button')['href']\n","    except : link=''\n","    try: title = it.find('a', 'title').text \n","    except : title=''\n","    try: penulis = it.find('span').text.replace('Penulis :','') \n","    except : penulis=''\n","\n","    if it != '':\n","      listJudul.append(title)\n","      listPenulis.append(penulis)\n","      req2 = requests.get(str(link), headers=headers)\n","      soup2 = BeautifulSoup(req2.text, 'html.parser')\n","      items2 = soup2.findAll('li',{'data-id':'id-1'})\n","      for it2 in items2:\n","        try : abstrak = it2.find('p',{'align':'justify'}).text\n","        except : abstrak=''\n","\n","        if it2 != '':\n","          listAbstrak.append(abstrak)\n","  \n","judul = pd.DataFrame(listJudul,columns=[\"Judul\"])\n","penulis = pd.DataFrame(listPenulis,columns=[\"Penulis\"])\n","abstrak = pd.DataFrame(listAbstrak,columns=[\"Abstrak\"])\n","data = pd.concat([penulis,judul, abstrak], axis=1) \n","data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWUqdy7ERyNT"},"outputs":[],"source":["TA=scrape_TA(10)\n","TA_result = pd.DataFrame(TA)\n","TA_result.columns = [\"NPM\", \"Judul\",\"Abstrak\",\"Prodi\"]\n","TA_result"]},{"cell_type":"markdown","metadata":{"id":"scJbfmI5VtDJ"},"source":["### Export To CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1jGPwCfVwFF"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = '/content/drive/My Drive/prosaindata/CrawlingWebPTA.csv'\n","with open(path, 'w', encoding = 'utf-8-sig') as f:\n","  TA_result.to_csv(f)"]},{"cell_type":"markdown","metadata":{"id":"9jGA03wrWIpF"},"source":["## TUGAS 3 (Crawling data Website Berita CNN)\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eBjRlvksWMM0"},"source":["### 1. Install modul Beautifulsoup dan requests"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ndft83IWO6Z"},"outputs":[],"source":["!pip install requests\n","!pip install BeautifulSoup4"]},{"cell_type":"markdown","metadata":{"id":"PuKHvyvyWQDf"},"source":["### 2. Import library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vqg07YSXWSmF"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"04uKFeyKWaS0"},"source":["### 3. Peroses crawling menggunakan bs4 dan request"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7-71OJ3Web-"},"outputs":[],"source":["#Inisialisasi Link URL\n","url = 'https://www.cnnindonesia.com/indeks'\n","\n","headers={\n","    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'\n","    }\n","\n","#inisialisasi list untuk memasukkan hasil crawling kedalam list\n","listJudul = []\n","listIsi = []\n","\n","#proses perulangan untuk crawling data\n","for page in range(1,4):\n","  req = requests.get(url+str(page), headers=headers)\n","  soup = BeautifulSoup(req.text, 'html.parser')\n","  items = soup.findAll('article')\n","  for it in items:\n","    try: link = it.find('a')['href']\n","    except : link=''\n","    try: title = it.find('h2', 'title').text \n","    except : title=''\n","    \n","    if title != '':\n","      listJudul.append(title)\n","\n","    if link != '':\n","      req2 = requests.get(str(link), headers=headers)\n","      soup2 = BeautifulSoup(req2.text, 'html.parser')\n","      items2 = soup2.findAll(\"div\", \"detail_text\")\n","      for it2 in items2:\n","        try : berita = it2.find('p').text\n","        except : berita=''\n","\n","        if berita != '':\n","          listIsi.append(berita)\n","\n","\n","df_Judul = pd.DataFrame(listJudul, columns=[\"Judul Berita\"])\n","df_Isi = pd.DataFrame(listIsi, columns=[\"Isi Berita\"])\n","\n","data = pd.concat([df_Judul, df_Isi], axis=1)\n","data = data.loc[0:50]\n","data\n"]},{"cell_type":"markdown","metadata":{"id":"AGi9x50SWjej"},"source":["### 4.Export To CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzyY_7XgWl6T"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = '/content/drive/My Drive/prosaindata/CrawlingBerita.csv'\n","with open(path, 'w', encoding = 'utf-8-sig') as f:\n","  data.to_csv(f)"]},{"cell_type":"markdown","metadata":{"id":"IsVhh-mHgne-"},"source":["## TUGAS 4 (Pipelines)"]},{"cell_type":"markdown","metadata":{"id":"s-t5qRBvoElz"},"source":["Pertama tama saya memisahkan kolom Petal Length, Petal Width, Sepal Length, dan Sepal Width + class dan ditambah masing-masing kolom id di csv. kemudian saya mengkonversi csv to sql menjadi script sql. setelah masing-masing kolom telah di ubah ke script sql, selanjutnya saya memasukkan data tersebut ke masing” aplikasi database yaitu mysql, sql server, dan postgres sql local + elephant. Pertama, kolom sepal length saya masukkan ke database postgressql local, kemudian kolom sepal width saya masukkkan ke database postgressql elephantsql, kolom petal length dimasukkan ke database mysql local, dan terakhir kolom petalwidth +class dimasukkan ke database sql server, semua dimasukkkan sesuai dengan tahapan masing” database tersebut dengan menggunakan script sql yang sudah dikonversi dari csv. kemudian setelah berhasil memasukkan ke semua database lanjut menjadikan 1 kolom-kolom tersebut. disini saya mencoba menggunakan orchest namun tidak bisa untuk yang local (hanya bisa postgrest elephantsql saja) sehingga saya mencoba menggabungkan data-data dari tiap database tersebut dengan menggunakan google colab."]},{"cell_type":"markdown","metadata":{"id":"jh-oURWWsi1F"},"source":["http://localhost:8888/?token=ea4f8fda93fa3a5e19da8685b1711e55e4d4db20098d712e"]},{"cell_type":"markdown","source":["### Mengambil data dari database SQL Server"],"metadata":{"id":"dGtQeavhepIv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-R3333si752y"},"outputs":[],"source":["import pyodbc \n","import pandas as pd\n","cnxn_str = (\"Driver={odbc driver 17 for sql server};\"\n","            \"Server=DESKTOP-GVA3L0V\\SQLEXPRESS;\"\n","            \"Database=prosain200411100082;\"\n","            \"Trusted_Connection=yes;\")\n","cnxn = pyodbc.connect(cnxn_str)\n","cursor = cnxn.cursor()\t\n","cursor.execute(\"SELECT * FROM iris_arff\") \n","row = cursor.fetchall() \n","cursor.close()\n","data=[]\n","for i in row:\n","    data.append([i[0],i[1],i[2]])\n","df_sqlServer = pd.DataFrame(data, columns=['id','petalwidth','class'])\n","df_sqlServer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2yi-TUpO9sqe"},"outputs":[],"source":["!pip install psycopg2"]},{"cell_type":"markdown","source":["### Mengambil data dari database postgreSQL elephant"],"metadata":{"id":"WCZ7oDmrfko_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qis-kMZ97bP"},"outputs":[],"source":["import psycopg2\n","import pandas as pd\n","\n","# Buat koneksi ke PostgreSQL.\n","conn = psycopg2.connect(database=\"rhwoswwx\", user=\"rhwoswwx\", password=\"2LqEviJ16iU8KE6PWVyjG0rdi_ZBgbHO\", host=\"tiny.db.elephantsql.com\")\n","\n","\n","# Buat cursor untuk menjalankan query SQL.\n","cur = conn.cursor()\n","\n","# Jalankan query SQL.\n","cur.execute(\"SELECT ROW_NUMBER() OVER () as id, sepalwidth FROM iris_sepalwidth;\")\n","\n","# Ambil hasil query.\n","hasil_query = cur.fetchall()\n","\n","df_postEle = pd.DataFrame(hasil_query, columns=[\"id\", \"sepalwidth\"])\n","\n","print(df_postEle)\n","\n","# Tutup cursor dan koneksi.\n","cur.close()\n","conn.close()\n","\n"]},{"cell_type":"markdown","source":["### Mengambil data dari database Postgres Local"],"metadata":{"id":"8vTlOrh_gWbw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQYQ2cOz9-yz"},"outputs":[],"source":["import psycopg2\n","import pandas as pd\n","\n","# Buat koneksi ke PostgreSQL.\n","conn = psycopg2.connect(database=\"prosaindata0082\", user=\"postgres\", password=\"12345\", host=\"localhost\", port=\"5432\")\n","\n","\n","# Buat cursor untuk menjalankan query SQL.\n","cur = conn.cursor()\n","\n","# Jalankan query SQL.\n","cur.execute(\"SELECT ROW_NUMBER() OVER () as id, sepallength FROM iris_arff;\")\n","\n","# Ambil hasil query.\n","hasil_query = cur.fetchall()\n","\n","df_postLocal = pd.DataFrame(hasil_query, columns=[\"id\", \"sepallength\"])\n","\n","print(df_postLocal)\n","\n","# Tutup cursor dan koneksi.\n","cur.close()\n","conn.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xRImBxd-BlS"},"outputs":[],"source":["!pip install mysqlclient\n","!pip install mysql-connector-python\n","!pip install pymysql"]},{"cell_type":"markdown","source":["### Mengambil data dari database localhost"],"metadata":{"id":"U21mkHbCfY5H"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"L9s-ncLG-Edj"},"outputs":[],"source":["import mysql.connector\n","import pandas as pd\n","\n","mydb = mysql.connector.connect(\n","  host=\"localhost\",\n","  user=\"root\",\n","  password=\"\",\n","  database=\"prosaindata20041110082\"\n",")\n","\n","mycursor = mydb.cursor()\n","\n","mycursor.execute(\"SELECT * FROM iris\")\n","\n","myresult = mycursor.fetchall()\n","mycursor.close()\n","df_mysql = pd.DataFrame(myresult, columns=['id','petallength'])\n","# df_mysql.drop(df_mysql.columns[[0]],axis=1,inplace=True)\n","df_mysql"]},{"cell_type":"markdown","source":["### Menggabungkan Empat Sumber data"],"metadata":{"id":"H0Os2pvdiGpB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CK2DtA5i-Hdq"},"outputs":[],"source":["# merge df\n","result = pd.concat([df_postLocal, df_postEle,df_mysql, df_sqlServer], axis=1)\n","# result = pd.merge(df_postLocal,df_sqlServer, how=\"inner\", on=[\"id\", \"id\"])\n","result"]},{"cell_type":"markdown","source":["### Menghapus Kolom ID"],"metadata":{"id":"Tq_NwGn4iKsj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"viJ70_dC-Kfe"},"outputs":[],"source":["result.drop(result.columns[[0,2,4,6]],axis=1,inplace=True)\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIPoG4NT-M-q"},"outputs":[],"source":["X = result.values[:, :4]\n","Y = result.values[:, 4]\n","print(X)"]},{"cell_type":"code","source":["X.shape"],"metadata":{"id":"PrRhEs-WihiN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y.shape"],"metadata":{"id":"bAsDiZzuikG2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model PCA"],"metadata":{"id":"1KcpBLdZiy3H"}},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","pca = PCA(n_components=2)"],"metadata":{"id":"Xr-nPVl3i31K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pca.fit(X)"],"metadata":{"id":"rJNHm3YAi6Tv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pca.components_"],"metadata":{"id":"xbe9u_Ldi-V7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Z = pca.transform(X)"],"metadata":{"id":"O-lw0MYkjAaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Z.shape"],"metadata":{"id":"Ksu4X8SZjCTZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Membagi Data Training dan Data Test\n","data traning sebesar 80% data test sebesar 20%"],"metadata":{"id":"iGhPFRPyjGLt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UGyecQU-PqP"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split( \n","    X, Y, test_size = 0.2, random_state = 100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p727J0tw-SMK"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","classifier = DecisionTreeClassifier()\n","classifier.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kARTttgD-Ueq"},"outputs":[],"source":["y_pred = classifier.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1aPYA8-W-Z5c"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","print (\" DecisionTree Accuracy : \",\n","    accuracy_score(y_test,y_pred)*100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9H5yfvbH-cmL"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","classifier = KNeighborsClassifier(n_neighbors=5)\n","classifier.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gsARmcWw-e6K"},"outputs":[],"source":["y_pred = classifier.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nCIzIfrv-g5u"},"outputs":[],"source":["print (\" KNN Accuracy : \",\n","    accuracy_score(y_test,y_pred)*100)"]},{"cell_type":"markdown","metadata":{"id":"9-vDeFesAkJr"},"source":["## Tugas 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Asc05wC9ENpw"},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","import seaborn as sns\n","sns.set()\n","import matplotlib.pyplot as plt\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOxBMZXpEWmH"},"outputs":[],"source":["iris_data = pd.read_csv(\"https://raw.githubusercontent.com/RBellaApriliaDamayanti22/Datasets/main/Iris.csv\",index_col='Id')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JiyTwLzsEXdZ"},"outputs":[],"source":["iris_data.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hnWuWdDCEljx"},"outputs":[],"source":["iris_data.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sCz0wQ-vFNGB"},"outputs":[],"source":["iris_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BVrddZC0FQWm"},"outputs":[],"source":["## Label encoding since the algorithms we are going to use do not take non numerical or boolean data as inputs\n","iris_data.Species.replace({'Iris-setosa':0,'Iris-versicolor':1, 'Iris-virginica':2},inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DK-qnn1OFURZ"},"outputs":[],"source":["iris_data.head()"]},{"cell_type":"markdown","source":["## TUGAS 6 (TIME SERIES)"],"metadata":{"id":"OpDlOl8X8LDO"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd"],"metadata":{"id":"W1s0h1t4AGss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_passenger = pd.read_csv('https://raw.githubusercontent.com/RBellaApriliaDamayanti22/prosaindata/main/airline-passengers.csv')\n","df_passenger"],"metadata":{"id":"DJmvnbxP8RER"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def split_sequence(sequence, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequence)):\n","    # find the end of this pattern\n","        end_ix = i + n_steps\n","\n","    # check if we are beyond the sequence\n","        if end_ix > len(sequence)-1:\n","            break\n","    # gather input and output parts of the pattern\n","    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","    X.append(seq_x)\n","    y.append(seq_y)\n","    return X, y\n"],"metadata":{"id":"WeKuypVbBWg4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_passenger.shape"],"metadata":{"id":"qEcghGwJHs8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new= df_passenger['Passengers'].values"],"metadata":{"id":"QGy5MS0S8mVU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new"],"metadata":{"id":"MIu0acsVCxdQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# transform univariate time series to supervised learning problem\n","from numpy import array\n","# split a univariate sequence into samples\n","def split_sequence(sequence, n_steps):\n","    X, y = list(), list()\n","    for i in range(len(sequence)):\n","    # find the end of this pattern\n","        end_ix = i + n_steps\n","    # check if we are beyond the sequence\n","        if end_ix > len(sequence)-1:\n","            break\n","    # gather input and output parts of the pattern\n","        # print(i, end_ix)\n","        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","        X.append(seq_x)\n","        y.append(seq_y)\n","    return array(X), array(y)\n","\n","X, y = split_sequence(new, 3)\n"],"metadata":{"id":"NYHuOYzdDGpr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_X = pd.DataFrame(X, columns=['Xt-2', 'Xt-1', 'Xt'])\n","df_y = pd.DataFrame(y, columns=['y'])"],"metadata":{"id":"kh0POw-qDPdR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_X.head()"],"metadata":{"id":"By4_wEqqE-oC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_X.shape"],"metadata":{"id":"PePnxerk-8pY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X= df_X.iloc[:,0:2]\n","y= df_X.iloc[:,-1]"],"metadata":{"id":"zQc_6r6_-_dS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"id":"cIzq3xTw_ANp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \n","from sklearn.preprocessing import MinMaxScaler\n","scaler= MinMaxScaler()\n","X_norm= scaler.fit_transform(X)\n","y_norm= scaler.fit_transform(y.values.reshape(-1,1))"],"metadata":{"id":"HmoNTSvt_D1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_norm"],"metadata":{"id":"zuPbKenZ_GrH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_norm"],"metadata":{"id":"F_2f6mU7_KB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import split_dataset\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X_norm, y_norm, test_size=0.2, random_state=0)"],"metadata":{"id":"Frl33-M9_Pmk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import knn\n","from sklearn.neighbors import KNeighborsRegressor\n","model_knn = KNeighborsRegressor(n_neighbors=3)\n","model_knn.fit(X_train, y_train)"],"metadata":{"id":"ByMLLJqV_S-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred=model_knn.predict(X_test)"],"metadata":{"id":"BiuRGUeW_VZ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred=pd.DataFrame(y_pred, columns=['y_pred'])"],"metadata":{"id":"38lX1oIQ_ZP6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test=pd.DataFrame(y_test, columns=['y_test'])"],"metadata":{"id":"H7vacpIe_cfz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","mean_squared_error(y_test, y_pred)"],"metadata":{"id":"f861rhxW_lE_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(y_test)"],"metadata":{"id":"CmhPz6AZ_lZx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(y_pred)"],"metadata":{"id":"rHBeV_Bh_r11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_y_test = pd.DataFrame(y_test,columns=['y_test'])\n","df_y_pred = pd.DataFrame(y_pred,columns=['y_pred'])\n","\n","df = pd.concat([df_y_test, df_y_pred], axis=1)"],"metadata":{"id":"HBynLmCs_uB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"MT4IVv8J_w57"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_excel('df_y.xlsx', index=False)"],"metadata":{"id":"xSU6owyl_zfw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.min()"],"metadata":{"id":"JaeHdNoW_2S0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.max()"],"metadata":{"id":"Reks9k7m_8YQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred"],"metadata":{"id":"Pce0G-Nu__IS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## UTS"],"metadata":{"id":"HjN9aLOfIUrs"}},{"cell_type":"markdown","source":["### Load Data"],"metadata":{"id":"Dz8lZyogcqXw"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"vaX9s3E9Ic5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/My Drive/prosaindata/"],"metadata":{"id":"ZPIAtIGiJXTD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#install library\n","!pip install sastrawi\n","!pip install swifter\n","!pip install gensim"],"metadata":{"id":"rDCKMPjBS4Sh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import library\n","import pandas as pd\n","import numpy as np\n","from string import punctuation\n","import re\n","import nltk"],"metadata":{"id":"dGylIG-pc41O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load data\n","df = pd.read_excel(\"tugas/dataset/Data_TA.xlsx\")\n","df.head()"],"metadata":{"id":"-RJsxriCS63J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"Pse6efdPS9Jp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"id":"G1Qa4C76TAO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.dropna()"],"metadata":{"id":"6T60A5zDTClC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"IrwDQvR4TGF4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"id":"Q0xyUeGHTIou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Label'].value_counts()"],"metadata":{"id":"wfdKO_ODTMp7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing Data"],"metadata":{"id":"tf--s3A0TP7J"}},{"cell_type":"markdown","source":["#### 1. Symbol & Punctuation Removal, case folding"],"metadata":{"id":"Ed9vO2lwdSYr"}},{"cell_type":"code","source":["#proses menghilangkan simbol dan emoji\n","def remove_text_special (text):\n","  text = text.replace('\\\\t',\"\").replace('\\\\n',\"\").replace('\\\\u',\"\").replace('\\\\',\"\")\n","  text = text.encode('ascii', 'replace').decode('ascii')\n","  return text.replace(\"http://\",\" \").replace(\"https://\", \" \")\n","df['Abstrak'] = df['Abstrak'].apply(remove_text_special)\n","print(df['Abstrak'])"],"metadata":{"id":"x7V4d0c9TUOO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_tanda_baca(text):\n","  text = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text)\n","  return text\n","\n","df['Abstrak'] = df['Abstrak'].apply(remove_tanda_baca)\n","df['Abstrak'].head(20)"],"metadata":{"id":"VkgtctcWTWim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#proses menghilangkan angka\n","def remove_numbers (text):\n","  return re.sub(r\"\\d+\", \"\", text)\n","df['Abstrak'] = df['Abstrak'].apply(remove_numbers)\n","df['Abstrak']"],"metadata":{"id":"fMNZZdxbTZvj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#proses casefolding\n","def casefolding(Comment):\n","  Comment = Comment.lower()\n","  return Comment\n","df['Abstrak'] = df['Abstrak'].apply(casefolding)\n","df['Abstrak']"],"metadata":{"id":"JWqRa2tBTdCM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Word Normalization"],"metadata":{"id":"kd4Of0hQdjYA"}},{"cell_type":"code","source":["#proses tokenisasi\n","# from nltk.tokenize import TweetTokenizer\n","nltk.download('punkt')\n","# def word_tokenize(text):\n","#   tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n","#   return tokenizer.tokenize(text)\n","\n","df['review_token'] = df['Abstrak'].apply(lambda sentence: nltk.word_tokenize(sentence))\n","df['review_token']"],"metadata":{"id":"cxxkcmmITfyz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Normalisasi kata tidak baku\n","normalize = pd.read_excel(\"tugas/dataset/Normalization Data.xlsx\")\n","\n","normalize_word_dict = {}\n","\n","for row in normalize.iterrows():\n","  if row[0] not in normalize_word_dict:\n","    normalize_word_dict[row[0]] = row[1]\n","\n","def normalized_term(comment):\n","  return [normalize_word_dict[term] if term in normalize_word_dict else term for term in comment]\n","\n","df['comment_normalize'] = df['review_token'].apply(normalized_term)\n","df['comment_normalize'].head(20)"],"metadata":{"id":"T-Y3iXcdTkOl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3. Tokenizing"],"metadata":{"id":"1yUFJWa3duav"}},{"cell_type":"markdown","source":["#### 4. Stopwords Removal"],"metadata":{"id":"Z14zeEy7dxl9"}},{"cell_type":"code","source":["#Stopword Removal\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","txt_stopwords = stopwords.words('indonesian')\n","\n","def stopwords_removal(filtering) :\n","  filtering = [word for word in filtering if word not in txt_stopwords]\n","  return filtering\n","\n","df['stopwords_removal'] = df['comment_normalize'].apply(stopwords_removal)\n","df['stopwords_removal'].head(20)"],"metadata":{"id":"hAFeZhIWTn2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#stopword removal 2\n","data_stopwords = pd.read_excel(\"tugas/dataset/list_stopwords.xlsx\")\n","print(data_stopwords)\n","\n","def stopwords_removal2(filter) :\n","  filter = [word for word in filter if word not in data_stopwords]\n","  return filter\n","\n","df['stopwords_removal_final'] = df['stopwords_removal'].apply(stopwords_removal2)\n","df['stopwords_removal_final'].head(20)"],"metadata":{"id":"VApw21x6Tq-X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 5. Stemming"],"metadata":{"id":"CPNmgL8kd6te"}},{"cell_type":"code","source":["#proses stem\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","import string\n","import swifter\n","factory = StemmerFactory()\n","stemmer = factory.create_stemmer()\n","\n","def stemming (term):\n","  return stemmer.stem(term)\n","\n","term_dict = {}\n","for document in df['stopwords_removal_final']:\n","  for term in document:\n","    if term not in term_dict:\n","      term_dict[term] = ''\n"],"metadata":{"id":"uQQq49nlTtY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(term_dict))\n","print(\"-----------------------------\")"],"metadata":{"id":"-BlzSFdRTv_3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for term in term_dict:\n","  term_dict[term] = stemming(term)\n","  print(term,\":\",term_dict[term])\n","\n","print(term_dict)\n","print(\"-----------------------------\")"],"metadata":{"id":"BNLI4PW-Tybc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_stemming(document):\n","  return [term_dict[term] for term in document]"],"metadata":{"id":"0lMVgwSzuPXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['stemming'] = df['stopwords_removal_final'].swifter.apply(get_stemming)"],"metadata":{"id":"CtiMqM3PT09w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df['stemming'])"],"metadata":{"id":"lExxaz6oT3js"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head(20)"],"metadata":{"id":"Cjnk7Qu4ecAU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Word Embedding Word2vec CBOW"],"metadata":{"id":"bLC0Aff3QVDA"}},{"cell_type":"code","source":["import gensim\n","from gensim.models import Word2Vec"],"metadata":{"id":"cg2cvn2Qeitx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create CBOW model\n","model1 = gensim.models.Word2Vec(df['stemming'], min_count = 1,\n","                              vector_size = 100, window = 5)\n"," \n","# Print results\n","print(\"Cosine similarity between 'teknologi' \" +\n","               \"and 'system' - CBOW : \",\n","    model1.wv.similarity('teknologi', 'system'))\n","     \n","print(\"Cosine similarity between 'teknologi' \" +\n","                 \"and 'mobile' - CBOW : \",\n","      model1.wv.similarity('teknologi', 'mobile'))"],"metadata":{"id":"5av612FHelBw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#getting similar word\n","sim_words = model1.wv.most_similar('teknologi')\n","sim_words"],"metadata":{"id":"RXSJLGvDenl4"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}